version: '3.7'
services:
  zookeeper:
    image: harbor-xili.yhglobal.cn/docker-compose/zookeeper:3.8.0-debian-10-r37
    container_name: zookeeper      
    deploy:
      resources:
        limits:
          memory: 600M
          cpus: "2.00"
    restart: always
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOO_ENABLE_AUTH: "no"
      ZOO_HEAP_SIZE: "100"
      ALLOW_ANONYMOUS_LOGIN: "yes"

  kafka:
    image: harbor-xili.yhglobal.cn/docker-compose/kafka:3.1.1-debian-10-r0
    container_name: kafka    
    restart: always
    deploy:
      resources:
        limits:
          memory: 600M
          cpus: "2.00"
    depends_on:
      - zookeeper
    ports:
      - 29092:29092
    environment:
      KAFKA_BROKER_ID: 1
      ALLOW_PLAINTEXT_LISTENER: "yes"
      KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CFG_LISTENERS: PLAINTEXT://:29092,EXTERNAL://:9093
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://127.0.0.1:29092,EXTERNAL://kafka:9093
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_CFG_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_HEAP_OPTS: "-Xms50m -Xmx200m"
 
  kafka-ui:
    image: harbor-xili.yhglobal.cn/docker-compose/kafka-ui:v0.6.0
    container_name: kafka-ui
    deploy:
      resources:
        limits:
          memory: 200M
          cpus: "2.00"
    ports:
      - "8888:8080"    
    restart: always   
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9093
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181

  redis:
    image: harbor-xili.yhglobal.cn/docker-compose/redis:7.0.9
    container_name: redis
    restart: always
    deploy:
      resources:
        limits:
          memory: 600M
          cpus: "2.00"
    command: redis-server
    ports:
      - "6379:6379"

  mysql:
    image: harbor-xili.yhglobal.cn/bitnami/mysql:8.0.31-debian-11-r30
    restart: always
    container_name: mysql
    deploy:
      resources:
        limits:
          memory: 800M
          cpus: "2.00"
    volumes:
      - ./my_custom.cnf:/opt/bitnami/mysql/conf/my_custom.cnf:ro    
    environment:
      - "MYSQL_DATABASE=sequenceid"
      - "MYSQL_ROOT_PASSWORD=1q2w3E*"
      - "TZ=Asia/Shanghai"
    ports:
      - 3306:3306
  
  sequenceid:
    image: harbor-xili.yhglobal.cn/docker-compose/sequenceid:1.0.10
    restart: always
    container_name: sequenceid
    deploy:
      resources:
        limits:
          memory: 1000M
          cpus: "2.00"
    environment:
      - "JAVA_OPTS=-Duser.timezone=GMT+08 -Xms50m -Xmx500m -Dspring.datasource.url=jdbc:mysql://mysql:3306/sequenceid?useUnicode=true&characterEncoding=UTF-8&autoReconnect=true&serverTimezone=Asia/Shanghai -Dspring.datasource.username=root -Dspring.datasource.password=1q2w3E*"
      - "TZ=Asia/Shanghai"
    ports:
      - 8080:8080

  apm-server:
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
    cap_drop:
      - ALL
    command:
      - apm-server
      - '-e'
      - '--httpprof'
      - ':6060'
      - '-E'
      - apm-server.rum.enabled=true
      - '-E'
      - apm-server.rum.event_rate.limit=1000
      - '-E'
      - 'apm-server.host=0.0.0.0:8200'
      - '-E'
      - apm-server.read_timeout=1m
      - '-E'
      - apm-server.shutdown_timeout=2m
      - '-E'
      - apm-server.write_timeout=1m
      - '-E'
      - logging.json=true
      - '-E'
      - logging.metrics.enabled=false
      - '-E'
      - monitoring.elasticsearch=true
      - '-E'
      - monitoring.enabled=true
      - '-E'
      - 'apm-server.rum.allow_headers=["x-custom-header"]'
      - '-E'
      - instrumentation.enabled=true
      - '-E'
      - instrumentation.profiling.cpu.enabled=true
      - '-E'
      - instrumentation.profiling.heap.enabled=true
      - '-E'
      - apm-server.kibana.enabled=true
      - '-E'
      - 'apm-server.kibana.host=kibana:5601'
      - '-E'
      - apm-server.agent.config.cache.expiration=30s
      - '-E'
      - apm-server.kibana.username=apm_server_user
      - '-E'
      - apm-server.kibana.password=changeme
      - '-E'
      - 'output.elasticsearch.hosts=["http://elasticsearch:9200"]'
      - '-E'
      - output.elasticsearch.username=apm_server_user
      - '-E'
      - output.elasticsearch.password=changeme
      - '-E'
      - output.elasticsearch.enabled=true
    container_name: apm-server
    restart: always
    deploy:
      resources:
        limits:
          memory: 600M
          cpus: "2.00"
    depends_on:
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    environment:
      - BEAT_STRICT_PERMS=false
    healthcheck:
      interval: 10s
      retries: 12
      test:
        - CMD
        - curl
        - '--write-out'
        - '''HTTP %{http_code}'''
        - '-k'
        - '--fail'
        - '--silent'
        - '--output'
        - /dev/null
        - 'http://localhost:8200/'
      timeout: 5s
    image: harbor-xili.yhglobal.cn/docker-compose/apm-server:7.16.2
    labels:
      - co.elastic.apm.stack-version=7.16.2
    logging:
      driver: json-file
      options:
        max-file: '5'
        max-size: 2m
    ports:
      - '127.0.0.1:8201:8200'
      - '127.0.0.1:6060:6060'

  elasticsearch:
    container_name: elasticsearch
    restart: always
    deploy:
      resources:
        limits:
          memory: 2000M
          cpus: "2.00"
    environment:
      - bootstrap.memory_lock=true
      - cluster.name=docker-cluster
      - cluster.routing.allocation.disk.threshold_enabled=false
      - discovery.type=single-node
      - path.repo=/usr/share/elasticsearch/data/backups
      - 'ES_JAVA_OPTS=-XX:UseAVX=2 -Xms1g -Xmx1g'
      - path.data=/usr/share/elasticsearch/data/7.16.2
      - xpack.security.authc.anonymous.roles=remote_monitoring_collector
      - xpack.security.authc.realms.file.file1.order=0
      - xpack.security.authc.realms.native.native1.order=1
      - xpack.security.authc.token.enabled=true
      - xpack.security.authc.api_key.enabled=true
      - xpack.security.enabled=true
      - xpack.monitoring.collection.enabled=true
      #- xpack.license.self_generated.type=trial
    healthcheck:
      interval: 20s
      retries: 10
      test:
        - CMD-SHELL
        - >-
          curl -s -k http://localhost:9200/_cluster/health | grep -vq
          '"status":"red"'
    image: harbor-xili.yhglobal.cn/docker-compose/elasticsearch:7.16.2
    labels:
      - co.elastic.apm.stack-version=7.16.2
      - co.elastic.metrics/module=elasticsearch
      - 'co.elastic.metrics/metricsets=node,node_stats'
      - 'co.elastic.metrics/hosts=http://$${data.host}:9200'
    logging:
      driver: json-file
      options:
        max-file: '5'
        max-size: 2m
    ports:
      - '127.0.0.1:9200:9200'
    ulimits:
      memlock:
        hard: -1
        soft: -1
    volumes:
      - 'esdata:/usr/share/elasticsearch/data'
      - './docker/elasticsearch/roles.yml:/usr/share/elasticsearch/config/roles.yml'
      - './docker/elasticsearch/users:/usr/share/elasticsearch/config/users'
      - './docker/elasticsearch/users_roles:/usr/share/elasticsearch/config/users_roles'
      - './docker/elasticsearch/service_tokens:/usr/share/elasticsearch/config/service_tokens'
  fleet_setup:
    command:
      - curl
      - '-X'
      - POST
      - '-H'
      - 'kbn-xsrf: 1'
      - 'http://admin:changeme@kibana:5601/api/fleet/setup'
    depends_on:
      kibana:
        condition: service_healthy
    image: harbor-xili.yhglobal.cn/docker-compose/elasticsearch:7.16.2
    restart: always
    deploy:
      resources:
        limits:
          memory: 600M
          cpus: "2.00"
  kibana:
    container_name: kibana
    restart: always
    deploy:
      resources:
        limits:
           memory: 1000M
           cpus: "2.00"
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      ELASTICSEARCH_HOSTS: 'http://elasticsearch:9200'
      ELASTICSEARCH_PASSWORD: changeme
      ELASTICSEARCH_USERNAME: kibana_system_user
      SERVER_HOST: 0.0.0.0
      SERVER_NAME: kibana.example.org
      STATUS_ALLOWANONYMOUS: 'true'
      TELEMETRY_ENABLED: 'false'
      I18N_LOCALE: zh-CN
      XPACK_APM_SERVICEMAPENABLED: 'true'
      XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY: fhjskloppd678ehkdfdlliverpoolfcr
      XPACK_FLEET_AGENTS_ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
      XPACK_MONITORING_ENABLED: 'true'
      XPACK_REPORTING_ROLES_ENABLED: 'false'
      XPACK_SECURITY_ENCRYPTIONKEY: fhjskloppd678ehkdfdlliverpoolfcr
      XPACK_SECURITY_LOGINASSISTANCEMESSAGE: >-
        Login&#32;details:&#32;`admin/changeme`.&#32;Further&#32;details&#32;[here](https://github.com/elastic/apm-integration-testing#logging-in).
      XPACK_SECURITY_SESSION_IDLETIMEOUT: 1M
      XPACK_SECURITY_SESSION_LIFESPAN: 3M
      XPACK_XPACK_MAIN_TELEMETRY_ENABLED: 'false'
    healthcheck:
      interval: 10s
      retries: 30
      start_period: 10s
      test:
        - CMD-SHELL
        - 'curl -s -k http://kibana:5601/api/status | grep -q ''Looking good'''
    image: harbor-xili.yhglobal.cn/docker-compose/kibana:7.16.2
    labels:
      - co.elastic.apm.stack-version=7.16.2
    logging:
      driver: json-file
      options:
        max-file: '5'
        max-size: 2m
    ports:
      - '127.0.0.1:5601:5601'
  wait-service:
    container_name: wait
    restart: always
    deploy:
      resources:
        limits:
          memory: 300M
          cpus: "2.00"
    depends_on:
      apm-server:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      kibana:
        condition: service_healthy
    image: harbor-xili.yhglobal.cn/docker-compose/busybox:1.35.0-musl
  
  filebeat: 
    image: harbor-xili.yhglobal.cn/docker-compose/filebeat:7.16.2
    container_name: filebeat      
    restart: always
    deploy:
      resources:
        limits:
          memory: 300M
          cpus: "2.00"
    command:
      - filebeat
      - -e 
      - -strict.perms=false
    volumes:
      - './docker/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml'


networks:
  default:
    name: apm-integration-testing

volumes:
  esdata:
    driver: local
